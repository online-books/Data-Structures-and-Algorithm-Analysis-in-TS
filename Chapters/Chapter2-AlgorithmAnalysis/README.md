## 算法分析

### 1 数学基础
---
估计算法资源消耗所需的分析需要一套正式的系统构架，因此先从某些数学定义开始
#### 定义

1.  如果存在正常数$c$和$n_0$使得当$N \ge n_0$时,$T(N) \le cf(N)$，则记为$T(N)=O(f(N))$
2.  如果存在正常数$c$和$n_0$使得当$N \ge n_0$时,$T(N) \ge cg(N)$，则记为$T(N)=\Omega(f(N))$
3.  $T(N)=\Theta(h(N))$当且仅当$T(N)=O(h(N))$且$T(N)= \Omega(h(N))$
4.  如果$T(N)=O(p(N))$且$T(N) \not ={\Theta(p(N))}$，则$T(N)=o(p(N))$
   
这些定义的目的是要在函数间建立一种相对的级别。给定两个函数，比较它们的相对增长率(relative rate of growth)。当$T(N)=O(f(N))$时，函数$T(N)$是在以不快于$f(N)$的速度增长；因此$f(N)$是$T(N)$的一个上界。与此同时，$f(N)=\Omega(T(N))$意味着$T(N)$是$f(N)$的一个下界。

作为例子，$N^3$增长比$N^2$快，因此可以说$N^2=O(N^3)$或$N^3=\Omega(N^2)$。如果$g(N)=2N^2$，那么$g(N)=O(N^4)$，$g(N)=O(N^3)$，$g(N)=O(N^2)$都是成立的，但最后一个是最好的答案。写法$g(N)=\Theta(N^2)$不仅表示$g(N)=O(N^2)$而且还表示结果会尽可能地好。

#### 几个重要法则

1. 如果$T_1(N)=O(f(N))$且$T_2(N)=O(g(N))$,那么
   
   (a) $T_1(N)+T_2(N)=max(O(f(N)),O(g(N)))$

   (b) $T_1(N)*T_2(N)$=O(f(N)*g(N))
2. 如果$T(N)$是一个$k$次多项式，则$T(N)=\Theta(N^k)$
3. 对任意常数$k$，$log^kN=O(N)$。它告诉我们对数增长得非常缓慢

有几点需要注意。首先，将常数项或低阶项放进大$O$是非常坏的习惯。不要写成$T(N)=O(2N^2)$或$T(N)=O(N^2+N)$。在需要大$O$表示的任何分析中，各种简化都是可能发生的。低阶项一般可以被忽略，二常数项也可以弃掉。此时，精度的要求是很低的。

第二，总能够通过计算 $\lim_{n \to \infty}\frac{f(n)}{g(n)}$来确定两个函数$f(N)$和$g(N)$的相对增长率。该极限有四种可能的值：

-   极限是$0$：意味着$f(N)=o(g(N))$
-   极限时$c \not ={0}$：意味着$f(N)=\Theta(g(N))$
-   极限是$\infty$:意味着$g(N)=o(f(N))$
-   极限摆动：二者无关

### 2 要分析的问题
---
要分析的最重要的资源一般说来就是运行时间，有几个因素影响程序的运行时间，典型的情形是输入的大小是主要的考虑方面。定义两个函数$T_{avg}(N)$和$T_{worst}(N)$，输入分别为$N$时，算法所花费的平均运行时间和最坏情况下的运行时间。显然，$T_{avg}(N) \le T_{worst}(N)$。

一般说来，若无相反的指定，则所需要的量是最坏情况下的运行时间。原因之一是它对所有的输入提供来一个界限，包括特别坏的输入，而平均情况分析不能提供这样的界。另一个原因是平均情况的界计算起来通常要困难得多。

#### 最大的子序列和问题

给定整数$A_1,A_2,...,A_N$（可能有负数），求$\sum_{k=i}^jA_k$的最大值（若所有整数均为负数，则最大子序列和为$0$）。